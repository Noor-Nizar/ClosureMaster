{"cells":[{"cell_type":"markdown","metadata":{},"source":["Kaggle Code Block"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:20.538585Z","iopub.status.busy":"2024-08-30T18:21:20.537609Z","iopub.status.idle":"2024-08-30T18:21:20.853627Z","shell.execute_reply":"2024-08-30T18:21:20.852378Z","shell.execute_reply.started":"2024-08-30T18:21:20.538534Z"},"trusted":true},"outputs":[],"source":["# import os\n","# from kaggle_secrets import UserSecretsClient\n","\n","# user_secrets = UserSecretsClient()\n","# GITHUB_PAT = user_secrets.get_secret(\"GITHUB_PAT_CM\")\n","\n","# !git clone \"https://username:{GITHUB_PAT}@github.com/Noor-Nizar/ClosureMaster.git\"\n","# os.chdir(\"ClosureMaster\")\n","# # !pip install -r 'requirements.txt' -q ## TODO add requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:23.300060Z","iopub.status.busy":"2024-08-30T18:21:23.299516Z","iopub.status.idle":"2024-08-30T18:21:26.586405Z","shell.execute_reply":"2024-08-30T18:21:26.585000Z","shell.execute_reply.started":"2024-08-30T18:21:23.299993Z"},"trusted":true},"outputs":[],"source":["from models.PlaceNet import PlaceNet\n","from helpers import logger, visualize_segmentation\n","from datasets import SegmentationDataset\n","import logging\n","import torch\n","\n","logger.setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:26.590294Z","iopub.status.busy":"2024-08-30T18:21:26.589430Z","iopub.status.idle":"2024-08-30T18:21:27.060202Z","shell.execute_reply":"2024-08-30T18:21:27.058580Z","shell.execute_reply.started":"2024-08-30T18:21:26.590238Z"},"trusted":true},"outputs":[],"source":["model_pn = PlaceNet()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:27.062248Z","iopub.status.busy":"2024-08-30T18:21:27.061714Z","iopub.status.idle":"2024-08-30T18:21:30.162523Z","shell.execute_reply":"2024-08-30T18:21:30.161271Z","shell.execute_reply.started":"2024-08-30T18:21:27.062194Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","torch.Size([1, 7, 480, 640])\n","torch.Size([1, 7, 240, 320])\n","torch.Size([1, 7, 120, 160])\n"]}],"source":["dummy_in_full = torch.ones((1,7,480,640))\n","dummy_in_half = torch.ones((1,7,240,320))\n","dummy_in_quarter = torch.ones((1,7,120,160))\n","\n","recon_full, recon_half, recon_quarter = model_pn(dummy_in_full, dummy_in_half, dummy_in_quarter)\n","\n","print(\"-\"*100)\n","print(recon_full.shape)\n","print(recon_half.shape)\n","print(recon_quarter.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:30.164154Z","iopub.status.busy":"2024-08-30T18:21:30.163784Z","iopub.status.idle":"2024-08-30T18:21:30.217224Z","shell.execute_reply":"2024-08-30T18:21:30.215969Z","shell.execute_reply.started":"2024-08-30T18:21:30.164116Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(1.1126, grad_fn=<AddBackward0>)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from helpers import WMSELoss\n","\n","loss = WMSELoss(recon_full, dummy_in_full)\n","loss"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:21:30.218772Z","iopub.status.busy":"2024-08-30T18:21:30.218441Z","iopub.status.idle":"2024-08-30T18:22:34.617315Z","shell.execute_reply":"2024-08-30T18:22:34.615943Z","shell.execute_reply.started":"2024-08-30T18:21:30.218738Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/Caskroom/miniforge/base/envs/mtpqt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/opt/homebrew/Caskroom/miniforge/base/envs/mtpqt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoImageProcessor, UperNetForSemanticSegmentation\n","from torch.utils.data import DataLoader\n","\n","# Initialize processor and model\n","model_base = \"openmmlab/upernet-swin-large\"\n","processor = AutoImageProcessor.from_pretrained(model_base)\n","model = UperNetForSemanticSegmentation.from_pretrained(model_base)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T18:23:48.734846Z","iopub.status.busy":"2024-08-30T18:23:48.734418Z","iopub.status.idle":"2024-08-30T18:23:48.746101Z","shell.execute_reply":"2024-08-30T18:23:48.744553Z","shell.execute_reply.started":"2024-08-30T18:23:48.734808Z"},"trusted":true},"outputs":[],"source":["# Replace this with the path to your dataset of images\n","image_dir = \"/Users/noornizar/LocalDocuments/ClosureMaster/images\"\n","\n","# Create dataset and dataloader\n","dataset = SegmentationDataset(image_dir, processor, test_n_samples=2)\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from helpers.utils import classify_objects, classify_objects_tensor_batched\n","from helpers.visualization import convert_to_rgb, convert_to_rgb_batched"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["pixel_values = next(iter(dataloader))\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Process each image in the dataset\n","s1, s2, s3 = next(iter(dataloader))\n","def dflow(pixel_values):\n","    with torch.no_grad():\n","        outputs = model(pixel_values)\n","        batch_size = pixel_values.shape[0]\n","        seg_list = processor.post_process_semantic_segmentation(outputs, target_sizes=[pixel_values.shape[2:]] * batch_size)\n","        seg = torch.stack(seg_list)\n","        cls_seg = classify_objects_tensor_batched(seg).unsqueeze(1)\n","        rgb_seg = convert_to_rgb_batched(seg)\n","        combined = torch.cat([pixel_values, cls_seg, rgb_seg], dim=1)\n","    return combined"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["combined_s1 = dflow(s1)    \n","combined_s2 = dflow(s2)\n","combined_s3 = dflow(s3)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 7, 240, 320])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["combined_s2.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","torch.Size([2, 7, 480, 640])\n","torch.Size([2, 7, 240, 320])\n","torch.Size([2, 7, 120, 160])\n"]}],"source":["recon_full, recon_half, recon_quarter = model_pn(combined_s1, combined_s2, combined_s3)\n","\n","print(\"-\"*100)\n","print(recon_full.shape)\n","print(recon_half.shape)\n","print(recon_quarter.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ... existing imports ...\n","from torch.optim import Adam\n","from tqdm import tqdm\n","\n","# Initialize model, optimizer, and loss function\n","model_pn = PlaceNet()\n","optimizer = Adam(model_pn.parameters(), lr=1e-3)\n","criterion = WMSELoss\n","\n","# Training loop\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_pn.to(device)\n","\n","for epoch in range(num_epochs):\n","    model_pn.train()\n","    epoch_loss = 0\n","\n","    for s1, s2, s3 in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","        optimizer.zero_grad()\n","\n","        # Process input data\n","        combined_s1 = dflow(s1.to(device))\n","        combined_s2 = dflow(s2.to(device))\n","        combined_s3 = dflow(s3.to(device))\n","\n","        # Forward pass\n","        recon_full, recon_half, recon_quarter = model_pn(combined_s1, combined_s2, combined_s3)\n","\n","        # Compute loss\n","        loss = criterion(recon_full, combined_s1) + \\\n","               criterion(recon_half, combined_s2) + \\\n","               criterion(recon_quarter, combined_s3)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    avg_loss = epoch_loss / len(dataloader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n","\n","# Save the trained model\n","torch.save(model_pn.state_dict(), \"placenet_model.pth\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4522584,"sourceId":9017251,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
